{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>MySQL 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> csv파일 병합 => 데이터가 많지 않아서 spark 보다 pandas로 로드하는 것이 유리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>사용일자</th>\n",
       "      <th>노선명</th>\n",
       "      <th>지하철역</th>\n",
       "      <th>승차총승객수</th>\n",
       "      <th>하차총승객수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20150101</td>\n",
       "      <td>2호선</td>\n",
       "      <td>낙성대</td>\n",
       "      <td>14586.0</td>\n",
       "      <td>14889.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20150101</td>\n",
       "      <td>2호선</td>\n",
       "      <td>사당</td>\n",
       "      <td>19233.0</td>\n",
       "      <td>20298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20150101</td>\n",
       "      <td>2호선</td>\n",
       "      <td>방배</td>\n",
       "      <td>5920.0</td>\n",
       "      <td>6065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20150101</td>\n",
       "      <td>2호선</td>\n",
       "      <td>서초</td>\n",
       "      <td>4379.0</td>\n",
       "      <td>4120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20150101</td>\n",
       "      <td>분당선</td>\n",
       "      <td>선정릉</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>1828.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       사용일자  노선명 지하철역   승차총승객수   하차총승객수\n",
       "0  20150101  2호선  낙성대  14586.0  14889.0\n",
       "1  20150101  2호선   사당  19233.0  20298.0\n",
       "2  20150101  2호선   방배   5920.0   6065.0\n",
       "3  20150101  2호선   서초   4379.0   4120.0\n",
       "4  20150101  분당선  선정릉   1972.0   1828.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import chardet\n",
    "import warnings\n",
    "from pandas.errors import ParserWarning\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=ParserWarning)\n",
    "\n",
    "folder_path = \"CsvFile\"\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith(\".csv\")]\n",
    "\n",
    "expected_columns = [\"사용일자\", \"노선명\", \"지하철역\", \"승차총승객수\", \"하차총승객수\"]\n",
    "df_list = []\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "\n",
    "    try:\n",
    "        # 1. 인코딩 자동 감지\n",
    "        with open(file_path, 'rb') as f:\n",
    "            raw_data = f.read(10000)\n",
    "            encoding_detected = chardet.detect(raw_data)['encoding']\n",
    "        \n",
    "        # 2. 감지된 인코딩으로 CSV 읽기\n",
    "        df = pd.read_csv(\n",
    "            file_path,\n",
    "            encoding=encoding_detected,\n",
    "            names=expected_columns,\n",
    "            header=0,\n",
    "            index_col=False, \n",
    "            on_bad_lines='skip'  # 문제 있는 줄 건너뛰기\n",
    "        )\n",
    "        \n",
    "        df_list.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {file_path} - {e}\")\n",
    "\n",
    "df_pd = pd.concat(df_list, ignore_index=True)\n",
    "df_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2109398 entries, 0 to 2109397\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   사용일자    int64  \n",
      " 1   노선명     object \n",
      " 2   지하철역    object \n",
      " 3   승차총승객수  float64\n",
      " 4   하차총승객수  float64\n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 80.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_pd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Spark로 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_PYTHON'] = r\"C:\\Python39\\python.exe\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = r\"C:\\Python39\\python.exe\"\n",
    "\n",
    "jar_path = os.path.abspath(\"C:/mysql-connector-j-8.3.0/mysql-connector-j-8.3.0.jar\").replace(\"\\\\\", \"/\")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MySQL Export\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.python.worker.memory\", \"2g\") \\\n",
    "    .config(\"spark.local.ip\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.python.worker.reuse\", \"true\") \\\n",
    "    .config(\"spark.jars\", f\"file:///{jar_path}\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "spark_df = spark.createDataFrame(df_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector(spark://127.0.0.1:62468/jars/mysql-connector-j-8.3.0.jar)\n"
     ]
    }
   ],
   "source": [
    "print(spark.sparkContext._jsc.sc().listJars())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, 사용일자: string, 노선명: string, 지하철역: string, 승차총승객수: string, 하차총승객수: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.withColumn('사용일자', to_date(col('사용일자'), 'yyyyMMdd'))\n",
    "spark_df = spark_df.withColumn('승차총승객수', col('승차총승객수').cast('integer'))\n",
    "spark_df = spark_df.withColumn('하차총승객수', col('하차총승객수').cast('integer'))\n",
    "\n",
    "spark_df = spark_df.toDF('date', 'line', 'station', 'riding', 'dropped')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.select(\"line\", \"station\", \"riding\", \"dropped\", \"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- line: string (nullable = true)\n",
      " |-- station: string (nullable = true)\n",
      " |-- riding: integer (nullable = true)\n",
      " |-- dropped: integer (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------+----------+\n",
      "|  line|station|riding|dropped|      date|\n",
      "+------+-------+------+-------+----------+\n",
      "| 2호선| 낙성대| 14586|  14889|2015-01-01|\n",
      "| 2호선|   사당| 19233|  20298|2015-01-01|\n",
      "| 2호선|   방배|  5920|   6065|2015-01-01|\n",
      "| 2호선|   서초|  4379|   4120|2015-01-01|\n",
      "|분당선| 선정릉|  1972|   1828|2015-01-01|\n",
      "|분당선| 가천대|  2512|   3332|2015-01-01|\n",
      "|분당선|   태평|  7637|   7899|2015-01-01|\n",
      "|분당선|   모란| 11155|  11269|2015-01-01|\n",
      "|분당선|   야탑| 13041|  13379|2015-01-01|\n",
      "|분당선|   서현| 12399|  12379|2015-01-01|\n",
      "+------+-------+------+-------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbc_url = \"jdbc:mysql://localhost:3306/seoulsubway\"\n",
    "table_name = \"information\"\n",
    "properties = {\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"\",\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}\n",
    "\n",
    "# repartition 적절히 조절\n",
    "spark_df = spark_df.repartition(4)\n",
    "\n",
    "# MySQL JDBC 드라이버 경로는 Spark 세션 생성 시 반드시 포함되어 있어야 함\n",
    "\n",
    "spark_df.write.format(\"jdbc\").options(\n",
    "    url=jdbc_url,\n",
    "    driver=\"com.mysql.cj.jdbc.Driver\",\n",
    "    dbtable=table_name,\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    batchSize=\"1000\"\n",
    ").mode(\"append\").save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------+-------+----------+\n",
      "| line|   station|riding|dropped|      date|\n",
      "+-----+----------+------+-------+----------+\n",
      "|2호선|      신림|  1000|   2000|2015-02-02|\n",
      "|2호선|      사당| 52581|  57270|2015-05-20|\n",
      "|2호선|      사당| 48177|  55576|2015-03-28|\n",
      "|2호선|  건대입구| 36312|  37886|2015-01-18|\n",
      "|2호선|      삼성| 60477|  61752|2015-08-05|\n",
      "|2호선|신정네거리| 12739|  12650|2015-10-15|\n",
      "|2호선|      잠실| 65187|  57843|2015-10-25|\n",
      "|2호선|신정네거리|  7232|   7140|2015-10-11|\n",
      "|2호선|    낙성대| 36059|  35395|2015-04-02|\n",
      "|2호선|      서초| 25457|  26631|2015-07-02|\n",
      "+-----+----------+------+-------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.jdbc(url=jdbc_url, table=table_name, properties=properties)\n",
    "df.createOrReplaceTempView(\"information_view\")\n",
    "\n",
    "result = spark.sql(\"\"\"\n",
    "    select *\n",
    "    from information_view\n",
    "    where line = '2호선'\"\"\")\n",
    "\n",
    "result.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mstop()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
